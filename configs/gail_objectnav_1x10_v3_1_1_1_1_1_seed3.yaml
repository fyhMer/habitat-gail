# Created by Yunhai Feng at 2022/5/5

# GAIL single episode v3
# pure gail imitation, no task reward (gail_reward_coef = 1.0)
# GAIL.DISCRIMINATOR.lr is decreased to 2.5e-5
# v3: use rnn in discriminator
# v3-1: use resnet18 instead of resnet50 in discriminator
# v3-1-1: reduce discriminator rnn layers: num_recurrent_layers = 1
# v3-1-1-1: discriminator_epoch = 1
# v3-1-1-1-1: GAIL.DISCRIMINATOR.lr = 1.0e-5
# v3-1-1-1-1-1: ppo_epoch=8, resnet_baseplanes=4
BASE_TASK_CONFIG_PATH: "configs/objectnav_expert_mp3d_1x10_seed3.yaml" ###
DEMO_TASK_CONFIG_PATH: "configs/objectnav_expert_mp3d_1x10_seed3.yaml" ###
CMD_TRAILING_OPTS: ["TASK_CONFIG.ENVIRONMENT.ITERATOR_OPTIONS.MAX_SCENE_REPEAT_STEPS", "50000"]
TRAINER_NAME: "gail"
ENV_NAME: "NavGAILEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
#VIDEO_OPTION: ["disk", "tensorboard"]
VIDEO_OPTION: ["disk"]
TENSORBOARD_DIR: "/home/fyh/Data/habitat/tb/gail_1x10_v3_1_1_1_1_1/seed3" ###
VIDEO_DIR: "/home/fyh/Data/video_dir/gail_1x10_v3_1_1_1_1_1/seed3" ###
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: "/home/fyh/Data/habitat/checkpoints/gail_1x10_v3_1_1_1_1_1/seed3" ###
NUM_ENVIRONMENTS: 2
SENSORS: ["DEPTH_SENSOR", "RGB_SENSOR"]
CHECKPOINT_FOLDER: "/home/fyh/Data/habitat/checkpoints/gail_1x10_v3_1_1_1_1_1/seed3" ###
NUM_UPDATES: 100000
LOG_INTERVAL: 10
NUM_CHECKPOINTS: 100
# Force PyTorch to be single threaded as
# this improves performance considerably
FORCE_TORCH_SINGLE_THREADED: True

EVAL:
  SPLIT: "train_1x10_seed3"

RL:
  SUCCESS_REWARD: 2.5
  SLACK_REWARD: -1e-3

  POLICY:
    name: "PointNavResNetPolicy"
    OBS_TRANSFORMS:
      ENABLED_TRANSFORMS: ("ResizeShortestEdge", "CenterCropper")

  PPO:
    # ppo params
    clip_param: 0.2
    ppo_epoch: 8 # 4
    num_mini_batch: 1
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-5
    max_grad_norm: 0.2
    num_steps: 64
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    reward_window_size: 50
    use_normalized_advantage: False

    hidden_size: 512

  DDPPO:
    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: NCCL
    # Visual encoder backbone
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True
    # Whether or not to reset the critic linear layer
    reset_critic: True

    # Model parameters
    backbone: resnet50
    rnn_type: LSTM
    num_recurrent_layers: 2

GAIL:
  use_double_buffer: True
  gail_reward_coef: 1.0 # 0.5
  task_reward_coef: 0.0 # note [v5 param]
  sparse_reward_only: False # useless [v5 param]
  is_demonstration_env: False

  DISCRIMINATOR:
    hidden_size: 512
    resnet_baseplanes: 32
    backbone: resnet18
    normalize_visual_inputs: False

    # new params added in v-3 >>>
    use_rnn: True
    num_recurrent_layers: 1
    rnn_type: LSTM
    # <<< end

    discriminator_epoch: 1 # 8
    num_mini_batch: 1
    lr: 1.0e-6 # 1.0e-5
    eps: 1e-5
    use_linear_lr_decay: False
    max_grad_norm: 0.2
